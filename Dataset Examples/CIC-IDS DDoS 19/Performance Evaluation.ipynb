{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25e5bf3-25a3-475b-b1f1-0487b13d307d",
   "metadata": {},
   "source": [
    "Reading labeled CSV files from the CIC_2019 dataset folder. Due to the dataset's large size, each CSV file is read individually, with columns related to ports, IPs, MAC addresses, and payloads being dropped. Additionally, the label count for each file is limited to a maximum of 5000. Unmatched rows have been removed, and the resulting DataFrame is exported. Users can adjust these settings based on their system requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd00abc6-d6cf-4380-a6e9-65b6a77ca39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CSV files: 100%|██████████| 929/929 [1:07:20<00:00,  4.35s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to process all CSV files in a folder\n",
    "def process_csvs_in_folder(input_folder):\n",
    "    # Initialize an empty DataFrame to store the combined results\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over all CSV files in the input folder with progress bar\n",
    "    csv_files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "    \n",
    "    for csv_file in tqdm(csv_files, desc=\"Processing CSV files\"):\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            file_path = os.path.join(input_folder, csv_file)\n",
    "            df = pd.read_csv(file_path, low_memory=False)\n",
    "            \n",
    "            # Drop unnecessary columns\n",
    "            df.drop(['id','expiration_id','src_ip','src_mac','src_oui','src_port','dst_ip','dst_mac','dst_oui','dst_port',\n",
    "                     'protocol','ip_version','vlan_id','tunnel_id','bidirectional_first_seen_ms','bidirectional_last_seen_ms',\n",
    "                     'src2dst_first_seen_ms','src2dst_last_seen_ms','dst2src_first_seen_ms','dst2src_last_seen_ms',\n",
    "                     'application_name', 'application_category_name', 'application_is_guessed', 'application_confidence',\n",
    "                     'requested_server_name','client_fingerprint','server_fingerprint','user_agent','content_type',\n",
    "                     'udps.payload_data','udps.delta_time','udps.packet_direction','udps.ip_size','udps.transport_size',\n",
    "                     'udps.payload_size','udps.syn','udps.cwr','udps.ece','udps.urg','udps.ack','udps.psh','udps.rst',\n",
    "                     'udps.fin','file'], axis=1, inplace=True)\n",
    "\n",
    "            # Drop rows with missing values\n",
    "            df.dropna(inplace=True)\n",
    "\n",
    "            # Remove rows where the label is 'No Match'\n",
    "            df = df[df['label'] != 'No Match']\n",
    "\n",
    "            # Limit the number of instances per class label to 5000\n",
    "            df = df.groupby('label').apply(lambda x: x.head(5000)).reset_index(drop=True)\n",
    "\n",
    "            # Append the processed DataFrame to the combined DataFrame\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {csv_file}: {e}\")\n",
    "\n",
    "    # Return the combined DataFrame\n",
    "    return combined_df\n",
    "\n",
    "# Example usage:\n",
    "input_folder = \"/scratch/user/syedwali/Datasets/CIC_2019/processed/labeled_csv\"\n",
    "df = process_csvs_in_folder(input_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68285f98-da45-4d79-8359-7b8392202e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing completed\n"
     ]
    }
   ],
   "source": [
    "print('processing completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469a73fb-d7bf-4cd8-85dd-4e92375d1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, save the combined DataFrame to a CSV\n",
    "output_file = \"/scratch/user/syedwali/Datasets/undersampled_CIC2019_dataset.csv\"\n",
    "df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd2afd79-64ac-4019-81da-15b2b975db67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "TFTP             950295\n",
       "DrDoS_NTP        917607\n",
       "DrDoS_DNS        893762\n",
       "DrDoS_SNMP       415000\n",
       "LDAP             290000\n",
       "DrDoS_LDAP       290000\n",
       "MSSQL            190000\n",
       "DrDoS_MSSQL      150000\n",
       "UDP              150000\n",
       "DrDoS_SSDP       106650\n",
       "DrDoS_UDP        105000\n",
       "DrDoS_NetBIOS     65000\n",
       "NetBIOS           55057\n",
       "BENIGN            53277\n",
       "Syn               42004\n",
       "Portmap            5608\n",
       "UDP-lag            5000\n",
       "UDPLag             1203\n",
       "WebDDoS             148\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96156efd-a51e-43f0-a149-48fb73d8553b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidirectional_duration_ms\n",
      "bidirectional_packets\n",
      "bidirectional_bytes\n",
      "src2dst_duration_ms\n",
      "src2dst_packets\n",
      "src2dst_bytes\n",
      "dst2src_duration_ms\n",
      "dst2src_packets\n",
      "dst2src_bytes\n",
      "bidirectional_min_ps\n",
      "bidirectional_mean_ps\n",
      "bidirectional_stddev_ps\n",
      "bidirectional_max_ps\n",
      "src2dst_min_ps\n",
      "src2dst_mean_ps\n",
      "src2dst_stddev_ps\n",
      "src2dst_max_ps\n",
      "dst2src_min_ps\n",
      "dst2src_mean_ps\n",
      "dst2src_stddev_ps\n",
      "dst2src_max_ps\n",
      "bidirectional_min_piat_ms\n",
      "bidirectional_mean_piat_ms\n",
      "bidirectional_stddev_piat_ms\n",
      "bidirectional_max_piat_ms\n",
      "src2dst_min_piat_ms\n",
      "src2dst_mean_piat_ms\n",
      "src2dst_stddev_piat_ms\n",
      "src2dst_max_piat_ms\n",
      "dst2src_min_piat_ms\n",
      "dst2src_mean_piat_ms\n",
      "dst2src_stddev_piat_ms\n",
      "dst2src_max_piat_ms\n",
      "bidirectional_syn_packets\n",
      "bidirectional_cwr_packets\n",
      "bidirectional_ece_packets\n",
      "bidirectional_urg_packets\n",
      "bidirectional_ack_packets\n",
      "bidirectional_psh_packets\n",
      "bidirectional_rst_packets\n",
      "bidirectional_fin_packets\n",
      "src2dst_syn_packets\n",
      "src2dst_cwr_packets\n",
      "src2dst_ece_packets\n",
      "src2dst_urg_packets\n",
      "src2dst_ack_packets\n",
      "src2dst_psh_packets\n",
      "src2dst_rst_packets\n",
      "src2dst_fin_packets\n",
      "dst2src_syn_packets\n",
      "dst2src_cwr_packets\n",
      "dst2src_ece_packets\n",
      "dst2src_urg_packets\n",
      "dst2src_ack_packets\n",
      "dst2src_psh_packets\n",
      "dst2src_rst_packets\n",
      "dst2src_fin_packets\n",
      "udps.srcdst_packet_size_variation\n",
      "udps.srcdst_udp_packet_count\n",
      "udps.udp_packet_count\n",
      "udps.srcdst_tcp_packet_count\n",
      "udps.tcp_packet_count\n",
      "udps.srcdst_ack_packet_count\n",
      "udps.ack_packet_count\n",
      "udps.srcdst_fin_packet_count\n",
      "udps.fin_packet_count\n",
      "udps.srcdst_rst_packet_count\n",
      "udps.rst_packet_count\n",
      "udps.srcdst_psh_packet_count\n",
      "udps.psh_packet_count\n",
      "udps.srcdst_syn_packet_count\n",
      "udps.syn_packet_count\n",
      "udps.srcdst_unique_ports_count\n",
      "udps.srcdst_icmp_packet_count\n",
      "udps.icmp_packet_count\n",
      "udps.srcdst_http_ports_count\n",
      "udps.http_ports_count\n",
      "udps.srcdst_bidirectional_duration_avg\n",
      "udps.bidirectional_duration_avg\n",
      "udps.srcdst_dns_port_count\n",
      "udps.dns_port_count\n",
      "udps.srcdst_dns_port_src_count\n",
      "udps.dns_port_src_count\n",
      "udps.srcdst_vul_ports_count\n",
      "udps.src2dst_packet_count\n",
      "udps.bidirectional_packet_count\n",
      "udps.srcdst_src2dst_packet_count\n",
      "udps.srcdst_bidirectional_packet_count\n",
      "flowid\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a699808-1147-46cb-8763-78db4d8ee7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['flowid'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e20745-2ba8-4764-99e0-e596513ad897",
   "metadata": {},
   "source": [
    "### Performance Evaluation with contextual Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81867a5b-68b0-464c-894f-8548ad4a9bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       BENIGN       1.00      1.00      1.00     15870\n",
      "    DrDoS_DNS       0.74      0.87      0.80    268037\n",
      "   DrDoS_LDAP       0.62      0.18      0.28     87011\n",
      "  DrDoS_MSSQL       0.71      0.71      0.71     44834\n",
      "    DrDoS_NTP       1.00      1.00      1.00    275179\n",
      "DrDoS_NetBIOS       0.88      0.85      0.87     19586\n",
      "   DrDoS_SNMP       0.57      0.58      0.57    124394\n",
      "   DrDoS_SSDP       0.58      0.55      0.56     31906\n",
      "    DrDoS_UDP       0.53      0.52      0.52     31279\n",
      "         LDAP       0.50      0.57      0.54     87285\n",
      "        MSSQL       0.78      0.77      0.77     57060\n",
      "      NetBIOS       0.83      0.95      0.89     16604\n",
      "      Portmap       0.77      0.51      0.62      1677\n",
      "          Syn       1.00      1.00      1.00     12534\n",
      "         TFTP       1.00      1.00      1.00    285230\n",
      "          UDP       0.61      0.63      0.62     45197\n",
      "      UDP-lag       0.39      0.33      0.36      1605\n",
      "       UDPLag       0.98      0.99      0.99       354\n",
      "      WebDDoS       0.95      1.00      0.98        42\n",
      "\n",
      "     accuracy                           0.80   1405684\n",
      "    macro avg       0.76      0.74      0.74   1405684\n",
      " weighted avg       0.80      0.80      0.79   1405684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming df is already defined and has a 'label' column\n",
    "X = df.drop('label', axis=1)  # Features (drop the label column)\n",
    "y = df['label']  # Labels\n",
    "\n",
    "# Split the data (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42,n_jobs=-1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c821d7c6-5c0c-4cd3-a364-2a58a6749f91",
   "metadata": {},
   "source": [
    "### Performance Evaluation without contextual Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af0b9a1-5c25-4781-b773-d14967caf601",
   "metadata": {},
   "source": [
    "To demonstrate the impact of extended contextual features on classification performance, we've removed all such features from our analysis. By doing so, we can observe the potential degradation in classification accuracy when contextual information is limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84afc75c-a49a-4b16-b845-79062571134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['udps.srcdst_packet_size_variation','udps.srcdst_udp_packet_count','udps.udp_packet_count',\n",
    "'udps.srcdst_tcp_packet_count','udps.tcp_packet_count','udps.srcdst_ack_packet_count',\n",
    "'udps.ack_packet_count','udps.srcdst_fin_packet_count','udps.fin_packet_count',\n",
    "'udps.srcdst_rst_packet_count','udps.rst_packet_count','udps.srcdst_psh_packet_count',\n",
    "'udps.psh_packet_count','udps.srcdst_syn_packet_count','udps.syn_packet_count','udps.srcdst_unique_ports_count',\n",
    "'udps.srcdst_icmp_packet_count','udps.icmp_packet_count','udps.srcdst_http_ports_count','udps.http_ports_count',\n",
    "'udps.srcdst_bidirectional_duration_avg','udps.bidirectional_duration_avg','udps.srcdst_dns_port_count',\n",
    "'udps.dns_port_count','udps.srcdst_dns_port_src_count','udps.dns_port_src_count','udps.srcdst_vul_ports_count',\n",
    "'udps.src2dst_packet_count','udps.bidirectional_packet_count','udps.srcdst_src2dst_packet_count',\n",
    "'udps.srcdst_bidirectional_packet_count'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd647470-b8c0-429e-8410-6d078a9e2e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       BENIGN       0.99      1.00      1.00     15870\n",
      "    DrDoS_DNS       0.49      0.96      0.65    268037\n",
      "   DrDoS_LDAP       0.35      0.01      0.02     87011\n",
      "  DrDoS_MSSQL       0.51      0.23      0.32     44834\n",
      "    DrDoS_NTP       0.99      1.00      1.00    275179\n",
      "DrDoS_NetBIOS       0.47      0.87      0.61     19586\n",
      "   DrDoS_SNMP       0.77      0.24      0.37    124394\n",
      "   DrDoS_SSDP       0.42      0.05      0.09     31906\n",
      "    DrDoS_UDP       0.42      0.02      0.05     31279\n",
      "         LDAP       0.40      0.00      0.01     87285\n",
      "        MSSQL       0.55      0.80      0.65     57060\n",
      "      NetBIOS       0.56      0.10      0.17     16604\n",
      "      Portmap       0.69      0.04      0.08      1677\n",
      "          Syn       0.89      0.99      0.94     12534\n",
      "         TFTP       1.00      1.00      1.00    285230\n",
      "          UDP       0.42      0.93      0.58     45197\n",
      "      UDP-lag       0.00      0.00      0.00      1605\n",
      "       UDPLag       0.55      0.53      0.54       354\n",
      "      WebDDoS       0.15      0.10      0.12        42\n",
      "\n",
      "     accuracy                           0.71   1405684\n",
      "    macro avg       0.56      0.47      0.43   1405684\n",
      " weighted avg       0.71      0.71      0.64   1405684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming df is already defined and has a 'label' column\n",
    "X = df.drop('label', axis=1)  # Features (drop the label column)\n",
    "y = df['label']  # Labels\n",
    "\n",
    "# Split the data (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42,n_jobs=-1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbfda22-ddd5-408c-aaaf-449694b495d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
