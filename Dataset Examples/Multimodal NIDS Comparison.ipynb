{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f899e018-fdde-49f4-ab51-ad70a08b4110",
   "metadata": {},
   "source": [
    "### Comparing Flow vs Flow+Payload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf8ec2-b570-4339-a8d1-c79c121b96aa",
   "metadata": {},
   "source": [
    "Reading CIC-IoT Undersampled Version having both flow and payload features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "21942d94-9975-425e-991e-0e020d33671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('Datasets/undersampled_iot23_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "749e6bcb-13b7-404a-bf80-8dd8351a52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get the count of instances per class\n",
    "target_instances = 2000\n",
    "\n",
    "# Step 2: Undersample or oversample each class to have exactly 2500 instances\n",
    "balanced_df = pd.DataFrame()  # Empty dataframe to store balanced data\n",
    "\n",
    "for label in df['label'].unique():\n",
    "    class_subset = df[df['label'] == label]\n",
    "    \n",
    "    # If class has more than 2500 instances, undersample\n",
    "    if len(class_subset) > target_instances:\n",
    "        class_subset = class_subset.sample(target_instances, random_state=42)\n",
    "    \n",
    "    # If class has less than 2500 instances, oversample\n",
    "    #elif len(class_subset) < target_instances:\n",
    "    #    class_subset = class_subset.sample(target_instances, replace=True, random_state=42)\n",
    "    \n",
    "    # Append the balanced class subset to the balanced dataframe\n",
    "    balanced_df = pd.concat([balanced_df, class_subset])\n",
    "\n",
    "# Reset index of the final balanced dataframe\n",
    "balanced_df = balanced_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7bb27d79-27ed-4e86-af23-b72fc00048e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping dictionary\n",
    "label_mapping = {\n",
    "    'Backdoor_Malware': 'webbased',\n",
    "    'BrowserHijacking': 'webbased',\n",
    "    'CommandInjection': 'webbased',\n",
    "    'DDoS-ACK_Fragmentation': 'ddos',\n",
    "    'DDoS-HTTP_Flood-': 'ddos',\n",
    "    'DDoS-ICMP_Flood': 'ddos',\n",
    "    'DDoS-ICMP_Fragmentation': 'ddos',\n",
    "    'DDoS-PSHACK_Flood': 'ddos',\n",
    "    'DDoS-RSTFINFlood': 'ddos',\n",
    "    'DDoS-SYN_Flood': 'ddos',\n",
    "    'DDoS-SlowLoris': 'ddos',\n",
    "    'DDoS-SynonymousIP_Flood': 'ddos',\n",
    "    'DDoS-TCP_Flood': 'ddos',\n",
    "    'DDoS-UDP_Flood': 'ddos',\n",
    "    'DDoS-UDP_Fragmentation': 'ddos',\n",
    "    'DNS_Spoofing': 'spoofing',\n",
    "    'DictionaryBruteForce': 'brute',\n",
    "    'DoS-HTTP_Flood': 'dos',\n",
    "    'DoS-SYN_Flood': 'dos',\n",
    "    'DoS-TCP_Flood': 'dos',\n",
    "    'DoS-UDP_Flood': 'dos',\n",
    "    'MITM-ArpSpoofing': 'spoofing',\n",
    "    'Mirai-udpplain': 'mirai',\n",
    "    'Recon-HostDiscovery': 'recon',\n",
    "    'Recon-PortScan': 'recon',\n",
    "    'SqlInjection': 'webbased',\n",
    "    'XSS': 'webbased',\n",
    "    'benign': 'benign'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'label' column\n",
    "balanced_df['label_mapped'] = balanced_df['label'].map(label_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3c8cdb42-edcb-4428-864c-02b717d2d76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29344\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "import ast \n",
    "import string\n",
    "# Function to convert hex values to ASCII string\n",
    "def hex_to_ascii(hex_list):\n",
    "    ascii_str = ''\n",
    "\n",
    "    #print(len(hex_list))\n",
    "    for hex_val in hex_list:\n",
    "\n",
    "    # Split each hex value into pairs and convert them to ASCII characters\n",
    "      # Split each hex value into pairs and convert them to ASCII characters\n",
    "      ascii_str += ''.join([chr(int(hex_val[i:i+2], 16)) for i in range(0, len(hex_val), 2)])\n",
    "      filtered_str = ''.join(filter(lambda x: x in string.printable, ascii_str))\n",
    "    #print(filtered_str)\n",
    "\n",
    "    return filtered_str\n",
    "\n",
    "# Convert each string representation to a list\n",
    "balanced_df['udps.payload_data_parsed'] = balanced_df['udps.payload_data'].apply(ast.literal_eval)\n",
    "balanced_df['string'] = balanced_df['udps.payload_data_parsed'].apply(hex_to_ascii)\n",
    "#s=balanced_df.dropna(subset=['string'])\n",
    "empty_rows = balanced_df['string'].str.strip().eq('')\n",
    "\n",
    "# Get the indices of the rows to be dropped\n",
    "indices_to_drop = empty_rows[empty_rows].index\n",
    "\n",
    "# Drop the rows from the DataFrame\n",
    "s = balanced_df.drop(indices_to_drop)\n",
    "\n",
    "# Reset the index after dropping rows\n",
    "s.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check the modified DataFrame\n",
    "print(len(indices_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d536302-4006-4826-b0d2-9332b7e0320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "f=s.dropna(subset=['label_mapped'])\n",
    "# Assuming 'data' contains the 'string' and 'label' columns\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split((f), f['label_mapped'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the training data and transform both train and test data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train['string'])\n",
    "#X_test_tfidf = tfidf.transform(X_test['string'])\n",
    "\n",
    "# Initialize the Random Forest Classifier with parallel processing (n_jobs=-1)\n",
    "rf_classifier = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "# Train the classifier on the TF-IDF features and labels\n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e62ade83-d7d1-44c6-83c8-0585cdf97f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Function to check if a word exists in WordNet\n",
    "def is_word_in_wordnet(word):\n",
    "    return wordnet.synsets(word)\n",
    "\n",
    "# Get the feature names (vocabulary terms)\n",
    "feature_names = np.array(tfidf.get_feature_names_out())\n",
    "\n",
    "# Create an empty set to store top terms across all classes\n",
    "top_terms = set()\n",
    "\n",
    "# For each class, get the top 300 terms based on the average TF-IDF score\n",
    "for class_label in y_train.unique():\n",
    "    # Select the training samples for this class\n",
    "    class_indices = np.where(y_train == class_label)\n",
    "    \n",
    "    # Calculate the mean TF-IDF score for each feature across the class samples\n",
    "    mean_tfidf_scores = X_train_tfidf[class_indices].mean(axis=0).A1  # Convert sparse matrix to a dense array\n",
    "    \n",
    "    # Get the indices of the top 300 terms\n",
    "    top_300_indices = mean_tfidf_scores.argsort()[-1000:][::-1]  # Sort and select top 300\n",
    "    \n",
    "    # Add the corresponding terms to the top_terms set\n",
    "    top_terms.update(feature_names[top_300_indices])\n",
    "\n",
    "# Filter feature names based on WordNet\n",
    "filtered_top_terms = [term for term in top_terms if is_word_in_wordnet(term)]\n",
    "\n",
    "# Restrict the vectorizer's vocabulary to the filtered top terms\n",
    "tfidf_restricted = TfidfVectorizer(vocabulary=filtered_top_terms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dae59c17-c8e9-42ac-b06e-bb34a756fb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['response', 'streaming', 'sep', 'english', 'corresponding', 'philips', 'cam', 'feb', 'hint', 'trusted', 'close', 'licensed', 'signed', 'dial', 'discover', 'fail', 'password', 'top', 'news', 'azure', 'each', 'request', 'chromium', 'fbi', 'intellectual', 'accept', 'link', 'access', 'parameter', 'under', 'yahoo', 'see', 'texts', 'options', 'chunked', 'data', 'match', 'malicious', 'age', 'images', 'chrome', 'has', 'null', 'are', 'debug', 'three', 'permanently', 'image', 'spider', 'east', 'label', 'resolution', 'help', 'invalid', 'string', 'must', 'client', 'nim', 'height', 'net', 'wrapper', 'upgrade', 'transfer', 'base', 'new', 'describe', 'array', 'origin', 'void', 'lin', 'hellman', 'mode', 'gmt', 'description', 'packages', 'development', 'html', 'timely', 'script', 'hub', 'code', 'agent', 'boa', 'self', 'length', 'personal', 'url', 'below', 'source', 'while', 'update', 'licenses', 'met', 'fps', 'offers', 'gecko', 'placeholder', 'example', 'butcher', 'synthesizer', 'hook', 'letter', 'device', 'footer', 'event', 'network', 'address', 'width', 'gca', 'hacked', 'open', 'contains', 'pass', 'play', 'crs', 'certification', 'copy', 'camera', 'here', 'object', 'generic', 'more', 'copying', 'write', '3er', 'not', 'found', 'last', 'server', 'input', 'weeks', 'mailing', 'software', 'channel', 'signify', 'title', 'type', 'call', 'set', 'result', 'form', 'protection', 'after', 'uploads', 'axis', 'stable', 'live', 'replace', 'off', 'malformed', 'http', 'catch', 'copyrighted', 'box', 'css', 'man', 'language', 'check', 'above', 'ted', 'send', 'confirmation', 'field', 'technologies', 'inc', 'value', 'vary', 'service', 'head', 'cling', 'usn', 'low', 'blue', 'high', 'profile', 'search', 'urn', 'avs', 'information', 'lug', 'flash', 'connection', 'validation', 'required', 'wade', 'illegal', 'port', 'bad', 'understand', 'delivery', 'starts', 'sub', 'post', 'win', 'instead', 'logo', 'requests', 'error', 'curl', 'wireless', 'packets', 'center', 'inner', 'hello', 'available', 'cros', 'such', 'https', 'level', 'repository', 'header', 'lat', 'exchange', 'block', 'line', 'safari', 'license', 'undefined', 'submit', 'email', 'appears', 'backdoor', 'ranges', 'action', 'var', 'path', 'push', 'mon', 'offer', 'nov', 'index', 'team', 'results', 'prefer', 'like', 'dms', 'beef', 'macintosh', 'unauthorized', 'function', 'sent', 'vulnerable', 'keep', 'rate', 'test', 'transitional', 'schemas', 'group', 'class', 'column', 'basic', 'moved', 'tas', 'cbc', 'browser', 'deflate', 'please', 'property', 'within', 'alive', 'rings', 'hidden', 'receive', 'default', 'video', 'may', 'dispatch', 'document', 'protected', 'policy', 'frame', 'color', 'obtain', 'oct', 'complete', 'media', 'user', 'location', 'bot', 'system', 'exec', 'true', 'deliver', 'tech', 'years', 'methods', 'method', 'pin', 'container', 'size', 'name', 'apache', 'waiting', 'respective', 'access_code', 'bytes', 'style', 'pid', 'content', 'website', 'audio', '4er', 'mas', 'demos', 'opts', 'window', 'get', 'modified', 'store', 'info', 'google', 'mac', 'public', 'windows', 'prod', 'date', 'acknowledgements', 'unknown', 'page', 'welcome', 'eindhoven', 'connectivity', 'scd', 'stm', 'application', 'returns', 'body', 'hereby', 'encoding', 'max', 'damn', 'services', 'callback', 'amp', 'false', 'allow', 'return', 'root', 'text', 'netherlands', 'product', 'host', 'alt', 'use', 'aus', 'purchase', 'selector', 'web', 'cat', 'try', 'sets', 'issued', 'list', 'version', 'there', 'exceeded', 'lighting', 'cache', 'solutions', 'bob', 'security', 'powered', 'auto', 'organization', 'aug', 'insecure', 'control', 'linux', 'expires', 'plain', 'requested', 'valid', 'channels', 'vulnerabilities', 'target', 'west', 'used', 'navigator', 'receipt', 'scheme', 'cookie', 'hue', 'www']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to filter terms\n",
    "def is_valid_term(term):\n",
    "    # Check if the term is more than 2 characters and does not consist of only digits\n",
    "    return len(term) > 2 and not term.isdigit()\n",
    "\n",
    "# Apply the filter to the list of terms\n",
    "filtered_top_terms = [term for term in filtered_top_terms if is_valid_term(term)]\n",
    "\n",
    "# Print the filtered terms\n",
    "print(filtered_top_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0e4e201b-2322-4f58-b1fb-d3c8b55a5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_restricted = TfidfVectorizer(vocabulary=filtered_top_terms)\n",
    "X_train_tfidf_restricted = tfidf_restricted.fit_transform(X_train['string'])\n",
    "X_test_tfidf_restricted = tfidf_restricted.transform(X_test['string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14c32de2-43f3-4407-8f2a-701f1e356a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_features = [\n",
    "    'bidirectional_duration_ms','bidirectional_packets','bidirectional_bytes','src2dst_duration_ms','src2dst_packets','src2dst_bytes',\n",
    "'dst2src_duration_ms','dst2src_packets','dst2src_bytes','bidirectional_min_ps','bidirectional_mean_ps',\n",
    "'bidirectional_stddev_ps','bidirectional_max_ps','src2dst_min_ps','src2dst_mean_ps','src2dst_stddev_ps','src2dst_max_ps',\n",
    "'dst2src_min_ps','dst2src_mean_ps','dst2src_stddev_ps','dst2src_max_ps','bidirectional_min_piat_ms','bidirectional_mean_piat_ms',\n",
    "'bidirectional_stddev_piat_ms','bidirectional_max_piat_ms','src2dst_min_piat_ms','src2dst_mean_piat_ms','src2dst_stddev_piat_ms',\n",
    "'src2dst_max_piat_ms','dst2src_min_piat_ms','dst2src_mean_piat_ms','dst2src_stddev_piat_ms','dst2src_max_piat_ms','bidirectional_syn_packets',\n",
    "'bidirectional_cwr_packets','bidirectional_ece_packets','bidirectional_urg_packets','bidirectional_ack_packets','bidirectional_psh_packets',\n",
    "'bidirectional_rst_packets','bidirectional_fin_packets','src2dst_syn_packets','src2dst_cwr_packets','src2dst_ece_packets',\n",
    "'src2dst_urg_packets','src2dst_ack_packets','src2dst_psh_packets','src2dst_rst_packets','src2dst_fin_packets','dst2src_syn_packets',\n",
    "'dst2src_cwr_packets','dst2src_ece_packets','dst2src_urg_packets','dst2src_ack_packets',\n",
    "'dst2src_psh_packets','dst2src_rst_packets','dst2src_fin_packets'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "344247f8-1354-4fa1-813b-e6714fac8788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the fixed-length payload data into a NumPy array\n",
    "X_payload = np.array(X_train_tfidf_restricted).tolist()\n",
    "# Extract the additional features from the DataFrame\n",
    "X_additional = X_train[flow_features].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8fee12-1940-42d5-a53d-e9b999a9a3c2",
   "metadata": {},
   "source": [
    "#### Training on both flow+payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf6f7229-c1a1-49b5-ae02-ada7a50956e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([X_additional, X_payload.toarray()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9281b6b7-5242-4b06-8c08-b80ce46a6f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9405\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.87      0.92      0.89       162\n",
      "       brute       0.96      0.92      0.94       145\n",
      "        ddos       0.99      0.96      0.97       717\n",
      "         dos       0.92      0.96      0.94       185\n",
      "       mirai       1.00      1.00      1.00       164\n",
      "       recon       0.73      0.73      0.73        15\n",
      "    spoofing       0.91      0.87      0.89       275\n",
      "    webbased       0.89      0.94      0.91       287\n",
      "\n",
      "    accuracy                           0.94      1950\n",
      "   macro avg       0.91      0.91      0.91      1950\n",
      "weighted avg       0.94      0.94      0.94      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming the labels are in a column named 'label_column'\n",
    "y = X_train['label_mapped']\n",
    "\n",
    "# Split the data into train and test sets (80% train, 20% test)\n",
    "X_train_mix, X_val_mix, y_train_mix, y_val_mix = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train_mix, y_train_mix)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_val_mix)\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "accuracy = accuracy_score(y_val_mix, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val_mix, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3697de2d-04bf-4623-8cf9-583247425da2",
   "metadata": {},
   "source": [
    "Evaluating on test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "901c1aa0-0cdc-447e-a2c4-ca869c6c3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the fixed-length payload data into a NumPy array\n",
    "X_payload2 = np.array(X_test_tfidf_restricted).tolist()\n",
    "# Extract the additional features from the DataFrame\n",
    "X_additional2 = X_test[flow_features].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "893b3eed-8833-4445-ac38-94003bf7fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_derived = np.hstack([X_additional2, X_payload2.toarray()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9af437fd-9ee9-4e40-bf1d-d01d5e445661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9405\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.85      0.91      0.88       359\n",
      "       brute       0.95      0.93      0.94       380\n",
      "        ddos       0.99      0.97      0.98      1830\n",
      "         dos       0.91      0.95      0.93       436\n",
      "       mirai       1.00      1.00      1.00       405\n",
      "       recon       0.62      0.67      0.65        52\n",
      "    spoofing       0.92      0.87      0.90       709\n",
      "    webbased       0.89      0.94      0.91       702\n",
      "\n",
      "    accuracy                           0.94      4873\n",
      "   macro avg       0.89      0.91      0.90      4873\n",
      "weighted avg       0.94      0.94      0.94      4873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test_derived)\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f853ea7-8de6-4d34-9c4c-8067e34af469",
   "metadata": {},
   "source": [
    "#### Training on only flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2d00ab05-4d3f-47cd-b3ed-8d51936c3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([X_additional])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d989840c-5773-42c3-84ba-5f3eb2966ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9405\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.88      0.92      0.90       162\n",
      "       brute       0.95      0.92      0.94       145\n",
      "        ddos       0.99      0.97      0.98       717\n",
      "         dos       0.93      0.96      0.94       185\n",
      "       mirai       1.00      1.00      1.00       164\n",
      "       recon       0.67      0.67      0.67        15\n",
      "    spoofing       0.90      0.86      0.88       275\n",
      "    webbased       0.89      0.93      0.91       287\n",
      "\n",
      "    accuracy                           0.94      1950\n",
      "   macro avg       0.90      0.90      0.90      1950\n",
      "weighted avg       0.94      0.94      0.94      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming the labels are in a column named 'label_column'\n",
    "y = X_train['label_mapped']\n",
    "\n",
    "# Split the data into train and test sets (80% train, 20% test)\n",
    "X_train_mix, X_val_mix, y_train_mix, y_val_mix = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train_mix, y_train_mix)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_val_mix)\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "accuracy = accuracy_score(y_val_mix, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val_mix, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887c44f-5451-4d91-a06b-2b7fe09a7194",
   "metadata": {},
   "source": [
    "Evaluating on test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2860c72c-2468-4b88-8b83-8c1f0c1bfbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_derived = np.hstack([X_additional2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "35d9f918-2968-4063-b1d1-6ec649b1512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9382\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.87      0.92      0.89       359\n",
      "       brute       0.95      0.93      0.94       380\n",
      "        ddos       0.99      0.97      0.98      1830\n",
      "         dos       0.91      0.92      0.92       436\n",
      "       mirai       1.00      1.00      1.00       405\n",
      "       recon       0.56      0.62      0.59        52\n",
      "    spoofing       0.92      0.88      0.90       709\n",
      "    webbased       0.88      0.93      0.90       702\n",
      "\n",
      "    accuracy                           0.94      4873\n",
      "   macro avg       0.88      0.90      0.89      4873\n",
      "weighted avg       0.94      0.94      0.94      4873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test_derived)\n",
    "\n",
    "# Evaluate the classifier's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdf658f-0a16-4720-8d81-e78ffbc3d5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
